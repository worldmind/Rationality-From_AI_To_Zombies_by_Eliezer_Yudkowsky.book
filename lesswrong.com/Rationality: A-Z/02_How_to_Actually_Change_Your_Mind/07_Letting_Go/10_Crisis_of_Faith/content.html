<blockquote><p>It ain’t a true crisis of faith unless things could just as easily go either way.</p><p>—Thor Shenkel</p></blockquote><p>Many in this world retain beliefs whose flaws a ten-year-old could point out, <i>if</i> that ten-year-old were hearing the beliefs for the first time. These are not subtle errors we’re talking about. They would be child's play for an <a href="https://www.lesswrong.com/lw/lm/affective_death_spirals/">unattached</a><i>&nbsp;</i>mind to relinquish, if the skepticism of a ten-year-old were applied <a href="https://www.lesswrong.com/lw/jy/avoiding_your_beliefs_real_weak_points/">without evasion</a>. As Premise Checker put it, "Had the idea of god not come along until the scientific age, only an exceptionally weird person would invent such an idea and pretend that it <a href="https://www.lesswrong.com/lw/jp/occams_razor/">explained</a> anything."</p><p>And yet skillful scientific specialists, even the major innovators of a field, even in this very day and age, do not apply that skepticism successfully. Nobel laureate Robert Aumann, of Aumann’s Agreement Theorem, is an Orthodox Jew: I feel reasonably confident in venturing that Aumann must, at one point or another, have questioned his faith. And yet he did not doubt <a href="https://www.lesswrong.com/lw/ib/the_proper_use_of_doubt/">successfully</a>.&nbsp; <a href="https://www.lesswrong.com/lw/jx/we_change_our_minds_less_often_than_we_think/">We change our minds less often than we think.</a></p><p>This should scare you down to the marrow of your bones. It means you can be a world-class scientist <i>and</i> conversant with Bayesian mathematics <i>and</i> still fail to reject a belief whose absurdity a fresh-eyed ten-year-old could see. It shows the invincible defensive position which a belief can create for itself, if it has long festered in your mind.</p><p>What does it take to defeat an error that has built itself a fortress?</p><p>But by the time you <i>know</i> it is an error, it is already defeated. The dilemma is not “How can I reject long-held false belief X?” but “How do I know if long-held belief X is false?” Self-honesty is at its most fragile when we’re not <i>sure</i> which path is the righteous one. And so the question becomes:</p><blockquote><p>How can we create in ourselves a true crisis of faith, that could just as easily go either way?</p></blockquote><p>Religion is the trial case we can all imagine.<a href="#fn2x74"><sup>2</sup></a> But if you have cut off all sympathy and now think of theists as evil mutants, then you won’t be able to imagine the real internal trials they face. You won’t be able to ask the question:</p><blockquote><p>What general strategy would a religious person have to follow in order to escape their religion?</p></blockquote><p>I’m sure that some, looking at this challenge, are already rattling off a list of standard atheist talking points—“They would have to admit that there wasn’t any Bayesian evidence for God’s existence,” “They would have to see the moral evasions they were carrying out to excuse God’s behavior in the Bible,” “They need to learn how to use Occam’s Razor—”</p><p>Wrong! Wrong wrong wrong! This kind of <a href="https://www.lesswrong.com/lw/ik/one_argument_against_an_army/">rehearsal</a>, where you just cough up points <i>you already thought of long before,</i> is <i>exactly</i> the style of thinking that keeps people within their current religions.&nbsp; If you stay with your <a href="https://www.lesswrong.com/lw/k5/cached_thoughts/">cached thoughts</a>, if your brain fills in the obvious answer so fast that you can't <a href="https://www.lesswrong.com/lw/k7/original_seeing/">see originally</a>, you surely will not be able to conduct a crisis of faith.</p><p>Maybe it’s just a question of not enough people reading <i>Gödel, Escher, Bach</i> at a sufficiently young age, but I’ve noticed that a large fraction of the population—even technical folk—have trouble following arguments that go this meta.<a href="#fn3x74"><sup>3</sup></a> On my more pessimistic days I wonder if the camel has two humps.</p><p>Even when it’s explicitly pointed out, some people seemingly <i>cannot follow the leap</i> from the object-level “Use Occam’s Razor! You have to see that your God is an unnecessary belief!” to the meta-level “Try to stop your mind from completing the pattern the usual way!” Because in the same way that all your rationalist friends talk about Occam’s Razor like it’s a good thing, and in the same way that Occam’s Razor leaps right up into your mind, so too, the obvious friend-approved religious response is “God’s ways are mysterious and it is presumptuous to suppose that we can understand them.” So for you to think that the <i>general</i> strategy to follow is “Use Occam’s Razor,” would be like a theist saying that the general strategy is to have faith.</p><p>“But—but Occam’s Razor really is better than faith! That’s not like preferring a different flavor of ice cream! Anyone can see, looking at history, that Occamian reasoning has been far more productive than faith—”</p><p>Which is all true. But beside the point. The point is that you, saying this, are rattling off a standard justification that’s already in your mind. The challenge of a crisis of faith is to handle the case where, possibly, our standard conclusions are <i>wrong</i> and our standard justifications are <i>wrong</i>. So if the standard justification for X is “Occam’s Razor!” and you want to hold a crisis of faith around X, you should be questioning if Occam’s Razor really endorses X, if your understanding of Occam’s Razor is correct, and—if you want to have sufficiently deep doubts—whether simplicity <i>is</i> the sort of criterion that has worked well historically in this case, or could reasonably be <i>expected</i> to work, et cetera. If you would advise a religionist to question their belief that “faith” is a good justification for X, then you should advise yourself to put forth an equally strong effort to question your belief that “Occam’s Razor” is a good justification for X.<a href="#fn4x74"><sup>4</sup></a></p><p>If “Occam’s Razor!” is your usual reply, your standard reply, the reply that all your friends give—then you’d better block your brain from instantly completing that pattern, if you’re trying to instigate a true crisis of faith.</p><p>Better to think of such rules as, “Imagine what a skeptic would say—and then imagine what they would say to your response—and then imagine what else they might say, that would be harder to answer.”</p><p>Or, “Try to think the thought that hurts the most.”</p><p>And above all, the rule:</p><blockquote><p>Put forth the same level of desperate effort that it would take for a theist to reject their religion.</p></blockquote><p>Because if you <i>aren’t</i> trying that hard, then—for all <i>you</i> know—your head could be stuffed full of nonsense as bad as religion.</p><p>Without a convulsive, wrenching effort to be rational, the kind of effort it would take to throw off a religion—then how dare you believe anything, when Robert Aumann believes in God?</p><p>Someone (I forget who) once observed that people had only until a certain age to reject their religious faith. Afterward they would have answers to all the objections, and it would be too late. That is the kind of existence you must surpass. This is a test of your strength as a rationalist, and it is very severe; but if you cannot pass it, you will be weaker than a ten-year-old.</p><p>But again, by the time you know a belief is an error, it is already defeated. So we’re not talking about a desperate, convulsive effort to <a href="https://www.lesswrong.com/lw/s3/the_genetic_fallacy/">undo the effects</a> of a religious upbringing, <i>after</i> you’ve come to the conclusion that your religion is wrong. We’re talking about a desperate effort to <i>figure out</i> if you should be throwing off the chains, or keeping them. Self-honesty is at its most fragile when we don’t <i>know</i> which path we’re supposed to take—that’s when rationalizations are not <i>obviously</i> sins.</p><p>Not every doubt calls for staging an all-out Crisis of Faith. But you should consider it when:</p><ul><li>A belief has long remained in your mind;</li><li>It is surrounded by a cloud of known arguments and refutations;</li><li>You have <a href="http://en.wikipedia.org/wiki/Sunk_cost">sunk costs</a> in it (time, money, public declarations);</li><li>The belief has <a href="https://www.lesswrong.com/lw/hp/feeling_rational/">emotional consequences</a> (note this does not make it wrong);</li><li>It has gotten mixed up in your personality generally.</li></ul><p>None of these warning signs are immediate disproofs. These attributes place a belief at risk for all sorts of dangers, and make it very hard to reject when it <i>is</i> wrong. And they hold for Richard Dawkins’s belief in evolutionary biology, not just the Pope’s Catholicism.</p><p>Nor does this mean that we’re only talking about different flavors of ice cream. Two beliefs can inspire equally deep emotional attachments without having equal evidential support. The point is not to have shallow beliefs, but to have a map that reflects the territory.</p><p>I emphasize this, of course, so that you can admit to yourself, “My belief has these warning signs,” without having to say to yourself, “My belief is false.”</p><p>But what these warning signs <i>do</i> mark is a belief that will take <i>more than an ordinary effort to doubt effectively</i>. It will take more than an ordinary effort to doubt in such a way that if the belief is in fact false, you will in fact reject it. And where you cannot doubt in this way, you are blind, because your brain will hold the belief <a href="https://www.lesswrong.com/lw/js/the_bottom_line/">unconditionally</a>.&nbsp; When a retina sends the same signal regardless of the photons entering it, <a href="https://www.lesswrong.com/lw/jl/what_is_evidence/">we call that eye blind</a>.</p><p>When should you stage a Crisis of Faith?</p><p>Again, think of the advice you would give to a theist: If you find yourself feeling a little unstable inwardly, but trying to rationalize reasons the belief is still solid, then you should probably stage a Crisis of Faith. If the belief is as solidly supported as gravity, you needn’t bother—but think of all the theists who would desperately want to conclude that God is as solid as gravity. So try to imagine what the skeptics out there would say to your “solid as gravity” argument. Certainly, one reason you might fail at a crisis of faith is that you never really sit down and question in the first place—that you never say, “Here is something I need to put effort into doubting properly.”</p><p>If your thoughts get that complicated, you should go ahead and stage a Crisis of Faith. Don’t try to do it haphazardly; don’t try it in an ad-hoc spare moment. Don’t rush to get it done with quickly, so that you can say, “I have doubted, as I was obliged to do.” That wouldn’t work for a theist, and it won’t work for you either. Rest up the previous day, so you’re in good mental condition. Allocate some uninterrupted hours. Find somewhere quiet to sit down. Clear your mind of all standard arguments; try to see from scratch. And make a desperate effort to put forth a true doubt that would destroy a false—and <i>only</i> a false—deeply held belief.</p><p>Elements of the Crisis of Faith technique have been scattered over many essays:</p><ul><li><a href="https://lesswrong.com/rationality/avoiding-your-belief-s-real-weak-points">Avoiding Your Belief’s Real Weak Points</a>—One of the first temptations in a crisis of faith is to doubt the strongest points of your belief, so that you can <a href="https://lesswrong.com/rationality/one-argument-against-an-army">rehearse</a> your good answers. You need to seek out the most painful spots, not the arguments that are most reassuring to consider.</li><li><a href="https://lesswrong.com/rationality/the-meditation-on-curiosity">The Meditation on Curiosity</a>—Roger Zelazny once distinguished between “wanting to be an author” versus “wanting to write,” and there is likewise a distinction between wanting to have investigated and wanting to investigate. It is not enough to say, “It is my duty to criticize my own beliefs”; you must be curious, and only uncertainty can create curiosity. Keeping in mind <a href="https://www.lesswrong.com/rationality/conservation-of-expected-evidence"><i>conservation of expected evidence</i></a> may help you <a href="https://www.lesswrong.com/rationality/update-yourself-incrementally"><i>update yourself incrementally</i></a>: for every <i>single</i> point that you consider, and each element of new argument and new evidence, you should not expect your beliefs to shift more (on average) in one direction than another. Thus you can be truly curious each time about how it will go.</li><li><a href="https://lesswrong.com/rationality/original-seeing">Original Seeing</a>—To prevent standard <a href="https://www.lesswrong.com/rationality/cached-thoughts">cached thoughts</a> from rushing in and completing the pattern.</li><li>The <a href="https://lesswrong.com/rationality/you-can-face-reality">Litany of Gendlin</a> and the <a href="https://www.lesswrong.com/rationality/the-meditation-on-curiosity">Litany of Tarski</a>—People can stand what is true, for they are already enduring it. If a belief is true, you will be better off believing it, and if it is false, you will be better off rejecting it. You would advise a religious person to try to visualize fully and deeply the world in which there is no God, and to, without excuses, come to the full understanding that <i>if</i> there is no God <i>then</i> they will be better off believing there is no God. If one cannot come to accept this on a deep emotional level, one will not be able to have a crisis of faith. So you should put in a sincere effort to visualize the <i>alternative</i> to your belief, the way that the best and highest skeptic would want you to visualize it. Think of the effort a religionist would have to put forth to imagine, without corrupting it for their own comfort, an atheist’s view of the universe.</li><li><a href="https://www.lesswrong.com/rationality/tsuyoku-naritai-i-want-to-become-stronger"><i>Tsuyoku Naritai!</i></a>—The drive to become stronger.</li><li><a href="https://www.lesswrong.com/rationality/the-genetic-fallacy">The Genetic Heuristic</a>—You should be extremely suspicious if you have many ideas suggested by a source that you now know to be untrustworthy, but by golly, it seems that all the ideas still ended up being right.</li><li><a href="https://www.lesswrong.com/rationality/the-importance-of-saying-oops">The Importance of Saying “Oops”</a>—It really is less painful to swallow the entire bitter pill in one terrible gulp.</li><li><a href="https://www.lesswrong.com/rationality/singlethink">Singlethink</a>—The opposite of doublethink. See the thoughts you flinch away from, that appear in the corner of your mind for just a moment before you refuse to think them. If you become aware of what you are not thinking, you can think it.</li><li><a href="https://www.lesswrong.com/rationality/affective-death-spirals">Affective Death Spirals</a> and <a href="https://www.lesswrong.com/rationality/resist-the-happy-death-spiral">Resist the Happy Death Spiral</a>—Affective death spirals are prime generators of false beliefs that it will take a Crisis of Faith to shake loose. But since affective death spirals can also get started around real things that are genuinely nice, you don’t have to admit that your belief is a lie, to try and resist the halo effect at every point—refuse false praise even of genuinely nice things. <a href="https://www.lesswrong.com/rationality/policy-debates-should-not-appear-one-sided">Policy debates should not appear one-sided.</a></li><li><a href="https://www.lesswrong.com/rationality/hold-off-on-proposing-solutions">Hold Off On Proposing Solutions</a>—Don’t propose any solutions until the problem has been discussed as thoroughly as possible. Make your mind hold off on knowing what its answer will be; and try for five minutes before giving up—both generally, and especially when pursuing the devil’s point of view.</li></ul><p>And these standard techniques, discussed in <i>How to Actually Change Your Mind</i> and <i>Map and Territory</i>, are particularly relevant:</p><ul><li>The sequence on <a href="https://www.lesswrong.com/rationality/the-bottom-line"><i>the bottom line</i></a> and <a href="https://www.lesswrong.com/rationality/rationalization"><i>rationalization</i></a>, which explains why it is always wrong to selectively argue one side of a debate.</li><li><a href="https://www.lesswrong.com/rationality/positive-bias-look-into-the-dark"><i>Positive bias</i></a>, <a href="https://www.lesswrong.com/rationality/knowing-about-biases-can-hurt-people"><i>motivated skepticism</i></a>, and <a href="https://www.lesswrong.com/rationality/motivated-stopping-and-motivated-continuation"><i>motivated stopping</i></a>, lest you selectively look for support, selectively look for counter-counterarguments, and selectively stop the argument before it gets dangerous. <a href="https://www.lesswrong.com/rationality/the-third-alternative">Missing alternatives</a> are a special case of stopping. A special case of motivated skepticism is <a href="https://www.lesswrong.com/rationality/the-proper-use-of-humility">fake humility</a>, where you bashfully confess that no one can know something you would rather not know. Don’t selectively demand too much <a href="https://www.lesswrong.com/rationality/absolute-authority">authority</a> of counterarguments.</li><li>Beware of <a href="https://www.lesswrong.com/rationality/semantic-stopsigns"><i>semantic stopsigns</i></a>, <a href="https://www.lesswrong.com/rationality/applause-lights"><i>applause lights</i></a>, and the choice between <a href="https://www.lesswrong.com/rationality/explain-worship-ignore"><i>explaining, worshiping, and ignoring</i></a> something.</li><li>Feel the weight of <a href="https://www.lesswrong.com/rationality/burdensome-details"><i>burdensome details</i></a>—each detail a separate burden, a point of crisis.</li></ul><p>But really, there’s rather a lot of relevant material, here and on <i>Overcoming Bias</i>. There are ideas I have yet to properly introduce. There is the concept of <i>isshokenmei</i>—the <i>desperate, extraordinary, convulsive effort</i> to be rational. The effort that it would take to surpass the level of Robert Aumann and all the great scientists throughout history who never broke free of their faiths.</p><p>The Crisis of Faith is only the critical point and sudden clash of the longer <i>isshoukenmei</i>—the lifelong uncompromising effort to be so incredibly rational that you rise above the level of stupid damn mistakes. It’s when you get a chance to use the skills that you’ve been practicing for so long, all-out against yourself.</p><p>I wish you the best of luck against your opponent. Have a wonderful crisis!</p><p><a href="#fn1x74-bk"><sup>1</sup></a>See “<a href="https://www.lesswrong.com/rationality/occam-s-razor">Occam’s Razor</a>” (in <i>Map and Territory</i>).</p><p><a href="#fn2x74-bk"><sup>2</sup></a>Readers born to atheist parents have missed out on a fundamental life trial, and must make do with the poor substitute of thinking of their religious friends.</p><p><a href="#fn3x74-bk"><sup>3</sup></a>See “Archimedes’s Chromophone” (<a href="https://lesswrong.com/lw/h5/archimedess_chronophone">http://lesswrong.com/lw/h5/archimedess_chronophone</a>) and “Chromophone Motivations” (<a href="https://lesswrong.com/lw/h6/chronophone_motivations">http://lesswrong.com/lw/h6/chronophone_motivations</a>).</p><p><a href="#fn4x74-bk"><sup>4</sup></a>Think of all the people out there who don’t understand the Minimum Description Length or Solomonoff induction formulations of Occam’s Razor, who think that Occam’s Razor outlaws many-worlds or the simulation hypothesis. They would need to question their formulations of Occam’s Razor and their notions of why simplicity is a good thing. Whatever X in contention you just justified by saying “Occam’s Razor!” is, I bet, not the same level of Occamian slam dunk as gravity.</p>
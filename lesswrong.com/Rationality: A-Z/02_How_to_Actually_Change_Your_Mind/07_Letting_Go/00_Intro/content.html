<div class="ory-row"><div class="ory-cell ory-cell-sm-12 ory-cell-xs-12"><div class="ory-cell-inner ory-cell-leaf"><div><p>Our natural state isn’t to change our minds like a Bayesian would. Getting the people in opposing tribes to notice what they’re really seeing won’t be as easy as reciting the axioms of probability theory to them. As Luke Muehlhauser writes, in <a href="http://lesswrong.com/lw/5i8/the_power_of_agency/">The Power of Agency</a>:</p><blockquote><p>You are not a Bayesian homunculus whose reasoning is “corrupted” by cognitive biases.</p><p>You just are cognitive biases.</p></blockquote><p>Confirmation bias, status quo bias, correspondence bias, and the like are not tacked on to our reasoning; they are its very substance.</p><p>That doesn’t mean that debiasing is impossible. We aren’t perfect calculators underneath all our arithmetic errors, either. Many of our mathematical limitations result from very deep facts about how the human brain works. Yet we can train our mathematical abilities; we can learn when to trust and distrust our mathematical intuitions, and share our knowledge, and help one another; we can shape our environments to make things easier on us, and build tools to offload much of the work.</p><p>Our biases are part of us. But there is a shadow of Bayesianism present in us as well, a flawed apparatus that really can bring us closer to truth. No homunculus—but still, some truth. Enough, perhaps, to get started.</p></div></div></div></div>
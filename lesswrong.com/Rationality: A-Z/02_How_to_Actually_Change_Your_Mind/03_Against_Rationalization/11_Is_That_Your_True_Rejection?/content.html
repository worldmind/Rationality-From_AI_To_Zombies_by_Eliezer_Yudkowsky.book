



  

  

  <p>It happens every now and then that someone encounters some of my transhumanist-side beliefs&#x2014;as opposed to my ideas having to do with human rationality&#x2014;strange, exotic-sounding ideas like superintelligence and Friendly AI. And the one rejects them. </p>

  <p>If the one is called upon to explain the rejection, not uncommonly the one says, &#x201C;Why should I believe anything Yudkowsky says? He doesn&#x2019;t have a PhD!&#x201D;</p>

  <p>And occasionally someone else, hearing, says, &#x201C;Oh, you should get a PhD, so that people will listen to you.&#x201D; Or this advice may even be offered by the same one who expressed disbelief, saying, &#x201C;Come back when you have a PhD.&#x201D;</p>

  <p>Now, there are good and bad reasons to get a PhD. This is one of the bad ones.</p>

  <p>There are many reasons why someone might actually have an initial adverse reaction to transhumanist theses. Most are matters of pattern recognition, rather than verbal thought: the thesis calls to mind an associated category like &#x201C;strange weird idea&#x201D; or &#x201C;science fiction&#x201D; or &#x201C;end-of-the-world cult&#x201D; or &#x201C;overenthusiastic youth.&#x201D;<span><sup><a href="#fn1x34" id="fn1x34-bk">1</a></sup></span><span id="x40-41001f1"> Immediately, at the speed of perception, the idea is rejected.</span></p>

  <p>If someone afterward says, &#x201C;Why not?&#x201D; this launches a search for justification, but the search won&#x2019;t necessarily hit on the true reason. By &#x201C;&#x2018;true reason,&#x201D; I don&#x2019;t mean the <em>best</em> reason that could be offered. Rather, I mean whichever causes were decisive as a matter of historical fact, at the <em>very first</em> moment the rejection occurred.</p>

  <p>Instead, the search for justification hits on the justifying-sounding fact, &#x201C;This speaker does not have a PhD.&#x201D; But I also don&#x2019;t have a PhD when I talk about human rationality, so why is the same objection not raised there?</p>

  <p>More to the point, if I <em>had</em> a PhD, people would not treat this as a decisive factor indicating that they ought to believe everything I say. Rather, the same initial rejection would occur, for the same reasons; and the search for justification, afterward, would terminate at a different stopping point.</p>

  <p>They would say, &#x201C;Why should I believe <em>you</em>? You&#x2019;re just some guy with a PhD! There are lots of those. Come back when you&#x2019;re well-known in your field and tenured at a major university.&#x201D;</p>

  <p>But do people <em>actually</em> believe arbitrary professors at Harvard who say weird things? Of course not.</p>

  <p>If you&#x2019;re saying things that sound <em>wrong</em> to a novice, as opposed to just rattling off magical-sounding technobabble about leptical quark braids in N + 2 dimensions; and if the hearer is a stranger, unfamiliar with you personally and unfamiliar with the subject matter of your field; then I suspect that the point at which the average person will actually start to grant credence overriding their initial impression, purely because of academic credentials, is somewhere around the Nobel Laureate level. If that. Roughly, you need whatever level of academic credential qualifies as &#x201C;beyond the mundane.&#x201D;</p>

  <p>This is more or less what happened to Eric Drexler, as far as I can tell. He presented his vision of nanotechnology, and people said, &#x201C;Where are the technical details?&#x201D; or &#x201C;Come back when you have a PhD!&#x201D; And Eric Drexler spent six years writing up technical details and got his PhD under Marvin Minsky for doing it. And <em>Nanosystems</em> is a great book. But did the same people who said, &#x201C;Come back when you have a PhD,&#x201D; actually change their minds at all about molecular nanotechnology? Not so far as I ever heard.</p>

  <p>This might be an important thing for young businesses and new-minted consultants to keep in mind&#x2014;that what your failed prospects <em>tell</em> you is the reason for rejection may not make the <em>real</em> difference; and you should ponder that carefully before spending huge efforts. If the venture capitalist says, &#x201C;If only your sales were growing a little faster!&#x201D; or if the potential customer says, &#x201C;It seems good, but you don&#x2019;t have feature X,&#x201D; that may not be the <em>true</em> rejection. Fixing it may, or may not, change anything.</p>

  <p>And it would also be something to keep in mind during disagreements. Robin Hanson and I share a belief that two rationalists should not agree to disagree: they should not have common knowledge of epistemic disagreement unless something is very wrong.<span><sup><a href="#fn2x34" id="fn2x34-bk">2</a></sup></span><span id="x40-41002f2"></span></p>

  <p>I suspect that, in general, if two rationalists set out to resolve a disagreement that persisted past the first exchange, they should expect to find that the true sources of the disagreement are either hard to communicate, or hard to expose. E.g.:</p>

  <ul>
    <li>Uncommon, but well-supported, scientific knowledge or math;</li>

    <li>Long inferential distances;</li>

    <li>Hard-to-verbalize intuitions, perhaps stemming from specific visualizations;</li>

    <li>Zeitgeists inherited from a profession (that may have good reason for it);</li>

    <li>Patterns perceptually recognized from experience;</li>

    <li>Sheer habits of thought;</li>

    <li>Emotional commitments to believing in a particular outcome;</li>

    <li>Fear that a past mistake could be disproved;</li>

    <li>Deep self-deception for the sake of pride or other personal benefits.</li>
  </ul>

  <p>If the matter were one in which <em>all</em> the true rejections could be <em>easily</em> laid on the table, the disagreement would probably be so straightforward to resolve that it would never have lasted past the first meeting.</p>

  <p>&#x201C;Is this my true rejection?&#x201D; is something that both disagreers should surely be asking <em>themselves</em>, to make things easier on the other person. However, attempts to directly, publicly psychoanalyze the other may cause the conversation to degenerate <em>very</em> fast, from what I&#x2019;ve seen.</p>

  <p>Still&#x2014;&#x201C;Is that your true rejection?&#x201D; should be fair game for Disagreers to humbly ask, if there&#x2019;s any productive way to pursue that sub-issue. Maybe the rule could be that you can openly ask, &#x201C;Is that simple straightforward-sounding reason your <em>true</em> rejection, or does it come from intuition-X or professional-zeitgeist-Y ?&#x201D; While the more embarrassing possibilities lower on the table are left to the Other&#x2019;s conscience, as their own responsibility to handle.</p>

  <div class="footnotes">
    

    <p><span><sup><a href="#fn1x34-bk" id="fn1x34">1</a></sup></span>See &#x201C;<a href="https://lesswrong.com/rationality/science-as-attire">Science as Attire</a>&#x201D; in <em>Map and Territory</em>.</p>

    <p><span><sup><a href="#fn2x34-bk" id="fn2x34">2</a></sup></span>See <span id="cite.0.Finney.2006">Hal Finney, &#x201C;Agreeing to Agree,&#x201D; <em>Overcoming Bias</em> (blog), 2006,</span> <a href="http://www.overcomingbias.com/2006/12/agreeing_to_agr.html">http://www.overcomingbias.com/2006/12/agreeing_to_agr.html</a>.</p>
  </div>


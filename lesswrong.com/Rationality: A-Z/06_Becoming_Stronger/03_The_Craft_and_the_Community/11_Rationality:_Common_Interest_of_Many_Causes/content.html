<p>It is a non-so-hidden agenda of this site, Less Wrong, that there are many causes which benefit from the spread of rationality&mdash;because it takes a little more rationality than usual to see their case, as a supporter, or even just a supportive bystander.&nbsp; Not just the obvious causes like atheism, but things like marijuana legalization&mdash;where you could wish that people were a bit more self-aware about their motives and the nature of signaling, and a bit more moved by inconvenient cold facts.&nbsp; The Institute Which May Not Be Named was merely an unusually extreme case of this, wherein it got to the point that after years of bogging down I threw up my hands and explicitly recursed on the job of creating rationalists.</p>
<p>But of course, not <em>all</em> the rationalists I create will be interested in my <em>own</em> project&mdash;<em>and that's fine.</em>&nbsp; You can't capture <em>all</em> the value you create, and trying can have poor side effects.</p>
<p>If the supporters of other causes are enlightened enough to think similarly...</p>
<p>Then all the causes which benefit from spreading rationality, can, perhaps, have something in the way of standardized material to which to point their supporters&mdash;a common task, centralized to save effort&mdash;and think of themselves as spreading a little rationality on the side.&nbsp; They won't capture all the value they create.&nbsp; And that's fine.&nbsp; They'll capture some of the value others create.&nbsp; Atheism has very little to do directly with marijuana legalization, but if both atheists and anti-Prohibitionists are willing to step back a bit and say a bit about the general, abstract principle of confronting a discomforting truth that interferes with a fine righteous tirade, then both atheism and marijuana legalization pick up some of the benefit from both efforts.</p>
<p>But this requires&mdash;I know I'm repeating myself here, but it's important&mdash;that you be willing not to capture all the value you create.&nbsp; It requires that, in the course of talking about rationality, you maintain an ability to temporarily <em>shut up</em> about your own cause <a href="/lw/2v/the_tragedy_of_the_anticommons/242#comments">even though it is the best cause ever</a>.&nbsp; It requires that you don't regard those other causes, and they do not regard you, as competing for a limited supply of rationalists with a limited capacity for support; but, rather, creating more rationalists and increasing their capacity for support.&nbsp; You only reap some of your own efforts, but you reap some of others' efforts as well.</p>
<p>If you and they don't agree on everything&mdash;especially priorities&mdash;you have to be willing to agree to <em>shut up</em> about the disagreement.&nbsp; (Except possibly in specialized venues, out of the way of the mainstream discourse, where such disagreements are explicitly prosecuted.)<a id="more"></a></p>
<p>A certain person who was taking over as the president of a certain organization once pointed out that the organization had not enjoyed much luck with its message of "This is <em>the best</em> thing you can do", as compared to e.g. the X-Prize Foundation's tremendous success conveying to rich individuals of "Here is <em>a cool</em> thing you can do."</p>
<p>This is one of those insights where you blink incredulously and then grasp how much sense it makes.&nbsp; The human brain <a href="http://www.overcomingbias.com/2007/05/scope_insensiti.html">can't grasp</a> <a href="http://www.overcomingbias.com/2007/05/one_life_agains.html">large stakes</a> and people are not anything remotely like expected utility maximizers, and we are generally altruistic akrasics.&nbsp; Saying, "This is the <em>best</em> thing" doesn't add much motivation beyond "This is a cool thing".&nbsp; It just establishes a much higher burden of proof.&nbsp; And invites invidious motivation-sapping comparison to all other good things you know (perhaps threatening to diminish <a href="http://www.overcomingbias.com/2007/05/scope_insensiti.html">moral satisfaction already purchased</a>).</p>
<p>If we're operating under the assumption that everyone by default is an altruistic akrasic (someone who wishes they could choose to do more)&mdash;or at least, that most potential supporters of interest fit this description&mdash;then fighting it out over which cause is the <em>best</em> to support, may have the effect of decreasing the overall supply of altruism.</p>
<p>"But," you say, "dollars are fungible; a dollar you use for one thing indeed cannot be used for anything else!"&nbsp; To which I reply:&nbsp; But human beings <em>really aren't</em> expected utility maximizers, as cognitive systems.&nbsp; Dollars come out of different mental accounts, cost different amounts of <em>willpower</em> (the true limiting resource) under different circumstances, people want to spread their donations around as an act of mental accounting to minimize the regret if a single cause fails, and telling someone about an additional cause may increase the total amount they're willing to help.</p>
<p>There are, of course, limits to this principle of benign tolerance.&nbsp; If someone has a project to help stray puppies get warm homes, then it's probably best to regard them as trying to exploit bugs in human psychology for their personal gain, rather than a worthy sub-task of the great common Neo-Enlightenment project of human progress.</p>
<p>But to the extent that something really is a task you would wish to see done on behalf of humanity... then invidious comparisons of that project to Your-Favorite-Project, may not help your own project as much as you might think.&nbsp; We may need to learn to say, by habit and in nearly all forums, "Here is <em>a cool</em> rationalist project", not, "Mine alone is <em>the highest-return in expected utilons per marginal dollar</em> project."&nbsp; If someone cold-blooded enough to maximize expected utility of fungible money without regard to emotional side effects <em>explicitly asks,</em> we could perhaps steer them to a <em>specialized</em> subforum where anyone willing to make the claim of <em>top</em> priority fights it out.&nbsp; Though if all goes well, those projects that have a strong claim to this kind of underserved-ness will get more investment and their marginal returns will go down, and the winner of the competing claims will no longer be clear.</p>
<p>If there are many rationalist projects that benefit from <a href="/lw/1e/raising_the_sanity_waterline/">raising the sanity waterline</a>, then their mutual tolerance and common investment in spreading rationality could conceivably exhibit a commons problem.&nbsp; But this doesn't seem too hard to deal with: if there's a group that's not willing to share the rationalists they create or mention to them that other Neo-Enlightenment projects might exist, then any common, centralized rationalist resources could remove the mention of their project as a cool thing to do.</p>
<p>Though all this is an idealistic and future-facing thought, the benefits&mdash;for all of us&mdash;could be finding some important things we're missing right now.&nbsp; So many rationalist projects have few supporters and far-flung; if we could all identify as elements of the Common Project of human progress, the Neo-Enlightenment, there would be a substantially higher probability of <a href="/lw/5v/church_vs_taskforce/">finding ten of us in any given city</a>.&nbsp; Right now, a lot of these projects are just a little lonely for their supporters.&nbsp; Rationality may not be <em>the most important thing in the world</em>&mdash;that, of course, is <a href="http://www.overcomingbias.com/2008/01/something-to-pr.html">the thing that we protect</a>&mdash;but it is <em>a cool</em> thing that more of us have in common.&nbsp; We might gain much from identifying ourselves also as rationalists.</p>
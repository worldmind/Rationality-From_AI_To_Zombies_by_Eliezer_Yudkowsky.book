<section xml:id="item_627DZcvme7nLDrbZu"
      xmlns="http://docbook.org/ns/docbook"
      version="5.0"
      xml:lang="en"
      xmlns:xlink="http://www.w3.org/1999/xlink"
      xmlns:xi="http://www.w3.org/2001/XInclude"
      xmlns:xl="http://www.w3.org/1999/xlink">
  <info>
    <title>Update Yourself Incrementally</title>
    <bibliosource class="uri">
      <link xlink:href="https://www.lesswrong.com/posts/627DZcvme7nLDrbZu/update-yourself-incrementally"></link>
    </bibliosource>
    <pubdate doc_status="draft">2022-06-30</pubdate>
  </info>
  <indexterm><primary>Rationality</primary></indexterm>
<indexterm><primary>Rationalization</primary></indexterm>
<indexterm><primary>Probabilistic Reasoning</primary></indexterm>
<indexterm><primary>Changing Your Mind</primary></indexterm>
<indexterm><primary>Conservation of Expected Evidence</primary></indexterm>
  <para><olink targetdoc="item_coGq3LC5Yn4vZiu6k" targetptr="item_9weLK2AJ9JEt2Tt8f">Politics is the mind-killer</olink>.  Debate is war, <olink targetdoc="item_coGq3LC5Yn4vZiu6k" targetptr="item_PeSzc9JTBxhaYRp9b">arguments are soldiers</olink>.  There is the temptation to search for ways to <olink targetdoc="item_PYQ2izdfDPTe5uJTG" targetptr="item_CqyJzDZWvGhhFJ7dY">interpret every possible experimental result</olink> to confirm your theory, like securing a citadel against every possible line of attack.  This you cannot do.  It is mathematically impossible. <olink targetdoc="item_PYQ2izdfDPTe5uJTG" targetptr="item_jiBFC7DcCrZjGmZnJ">For every expectation of evidence, there is an equal and opposite expectation of counterevidence.</olink></para>
<para>But it’s okay if your cherished belief isn’t <emphasis role="italic">perfectly</emphasis> defended. If the hypothesis is that the coin comes up heads 95% of the time, then one time in twenty you will expect to see what looks like contrary evidence. This is okay. It’s normal. It’s even expected, so long as you’ve got nineteen supporting observations for every contrary one. A probabilistic model can <link xl:href="https://www.lesswrong.com/posts/vrHRcEDMjZcx5Yfru/i-defy-the-data">take a hit or two</link>, and still survive, so long as the hits don&apos;t <emphasis role="italic">keep on</emphasis> coming in.</para>
<para>Yet it is widely believed, especially in the court of public opinion, that a true theory can have <emphasis role="italic">no</emphasis> failures and a false theory <emphasis role="italic">no</emphasis> successes.</para>
<para>You find people holding up a single piece of what they conceive to be evidence, and claiming that their theory can “explain” it, as though this were all the support that any theory needed. Apparently a false theory can have <emphasis role="italic">no</emphasis> supporting evidence; it is impossible for a false theory to fit even a single event. Thus, a single piece of confirming evidence is all that any theory needs.</para>
<para>It is only slightly less foolish to hold up a single piece of <emphasis role="italic">probabilistic</emphasis> counterevidence as disproof, as though it were impossible for a correct theory to have even a <emphasis role="italic">slight</emphasis> argument against it. But this is how humans have argued for ages and ages, trying to defeat all enemy arguments, while denying the enemy even a single shred of support. People want their debates to be one-sided; they are accustomed to a world in which their preferred theories have not one iota of antisupport. Thus, allowing a single item of probabilistic counterevidence would be the end of the world.</para>
<para>I just know someone in the audience out there is going to say, “But you <emphasis role="italic">can’t</emphasis> concede even a single point if you want to win debates in the real world! If you concede that any counterarguments exist, the Enemy will harp on them over and over—you can’t let the Enemy do that! You’ll <emphasis role="italic">lose!</emphasis> What could be more viscerally terrifying than <emphasis role="italic">that?</emphasis>”</para>
<para>Whatever. Rationality is not for winning debates, it is for deciding which side to join. If you’ve already decided which side to argue for, the work of rationality is <emphasis role="italic">done</emphasis> within you, whether well or poorly. But how can you, yourself, decide which side to argue? If <emphasis role="italic">choosing the wrong side</emphasis> is viscerally terrifying, even just a little viscerally terrifying, you’d best integrate <emphasis role="italic">all</emphasis> the evidence.</para>
<para>Rationality is not a walk, but a dance. On each step in that dance your foot should come down in exactly the correct spot, neither to the left nor to the right. Shifting belief upward with each iota of confirming evidence. Shifting belief downward with each iota of contrary evidence. Yes, <emphasis role="italic">down.</emphasis> Even with a correct model, if it is not an exact model, you will sometimes need to revise your belief <emphasis role="italic">down.</emphasis></para>
<para>If an iota or two of evidence happens to countersupport your belief, that’s okay. It happens, sometimes, with probabilistic evidence for non-exact theories. (If an exact theory fails, you <emphasis role="italic">are</emphasis> in trouble!) Just shift your belief downward a little—the probability, the odds ratio, or even a nonverbal weight of credence in your mind. Just shift downward a little, and <olink targetdoc="item_PYQ2izdfDPTe5uJTG" targetptr="item_jiBFC7DcCrZjGmZnJ">wait for more evidence</olink>. If the theory is true, supporting evidence will come in shortly, and the probability will climb again. If the theory is false, you don’t really want it anyway.</para>
<para>The problem with using black-and-white, binary, qualitative reasoning is that any single observation either destroys the theory or it does not. When not even a single contrary observation is allowed, <link xl:href="https://www.lesswrong.com/posts/vrHRcEDMjZcx5Yfru/i-defy-the-data">it creates cognitive dissonance and has to be argued away</link>. And this rules out incremental progress; it rules out correct integration of all the evidence. Reasoning probabilistically, we realize that on average, a correct theory will generate a greater weight of support than countersupport. And so you can, <emphasis role="italic">without fear,</emphasis> say to yourself: “This is gently contrary evidence, I will shift my belief downward.” Yes, <emphasis role="italic">down.</emphasis> It does not destroy your cherished theory. That is qualitative reasoning; think quantitatively.</para>
<para><olink targetdoc="item_PYQ2izdfDPTe5uJTG" targetptr="item_jiBFC7DcCrZjGmZnJ">For every expectation of evidence, there is an equal and opposite expectation of counterevidence.</olink> On every occasion, you must, on average, anticipate revising your beliefs downward as much as you anticipate revising them upward. If you think you already know what evidence will come in, then you must already be fairly sure of your theory—probability close to 1—which doesn’t leave much room for the probability to go further upward. And however unlikely it seems that you will encounter disconfirming evidence, the resulting downward shift must be large enough to precisely balance the anticipated gain on the other side. The weighted mean of your expected posterior probability must equal your prior probability.</para>
<para>How silly is it, then, to be <olink targetdoc="item_PYQ2izdfDPTe5uJTG" targetptr="item_fAuWLS7RKWD2npBFR">terrified</olink> of revising your probability downward, if you’re bothering to investigate a matter at all? On average, you must anticipate as much downward shift as upward shift from every individual observation.</para>
<para>It may perhaps happen that an iota of antisupport comes in again, and again and again, while new support is slow to trickle in. You may find your belief drifting downward and further downward. Until, finally, you realize from which quarter the winds of evidence are blowing against you. In that moment of realization, there is no point in constructing excuses. In that moment of realization, you have <emphasis role="italic">already relinquished</emphasis> your cherished belief. Yay! Time to celebrate! Pop a champagne bottle or send out for pizza! You can’t become stronger by keeping the beliefs you started with, after all.</para>

  
</section>

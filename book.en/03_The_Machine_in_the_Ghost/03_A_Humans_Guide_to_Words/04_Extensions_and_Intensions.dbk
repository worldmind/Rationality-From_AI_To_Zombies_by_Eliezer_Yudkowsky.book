<section xml:id="item_HsznWM9A7NiuGsp28"
      xmlns="http://docbook.org/ns/docbook"
      version="5.0"
      xml:lang="en"
      xmlns:xlink="http://www.w3.org/1999/xlink"
      xmlns:xi="http://www.w3.org/2001/XInclude"
      xmlns:xl="http://www.w3.org/1999/xlink">
  <info>
    <title>Extensions and Intensions</title>
    <bibliosource class="uri">
      <link xlink:href="https://www.lesswrong.com/posts/HsznWM9A7NiuGsp28/extensions-and-intensions"></link>
    </bibliosource>
    <pubdate doc_status="draft">2021-03-14</pubdate>
  </info>
  <indexterm><primary>Distinctions</primary></indexterm>
<indexterm><primary>Philosophy of Language</primary></indexterm>
<indexterm><primary>Rationality</primary></indexterm>
  <blockquote>
  <para> &quot;What is red?&quot;</para>
  <para>&quot;Red is a color.&quot;</para>
  <para>&quot;What&apos;s a color?&quot;</para>
  <para>&quot;A color is a property of a thing.&quot;</para>
</blockquote>
<para>But what is a thing?  And what&apos;s a property?  Soon the two are lost in a maze of words defined in other words, the problem that Steven Harnad once <link xl:href="http://www.ecs.soton.ac.uk/%7Eharnad/Papers/Harnad/harnad90.sgproblem.html">described</link> as trying to learn Chinese from a Chinese/Chinese dictionary.</para>
<para>Alternatively, if you asked me &quot;What is red?&quot; I could point to a stop sign, then to someone wearing a red shirt, and a traffic light that happens to be red, and blood from where I accidentally cut myself, and a red business card, and then I could call up a color wheel on my computer and move the cursor to the red area.  This would probably be sufficient, though if you know what the word &quot;No&quot; means, the <olink targetdoc="item_PYQ2izdfDPTe5uJTG" targetptr="item_rmAbiEKQDpDnZzcRf">truly strict</olink> would insist that I point to the sky and say &quot;No.&quot;</para>
<para>I think I stole this example from S. I. Hayakawa—though I&apos;m really not sure, because I heard this way back in the indistinct blur of my childhood.  (When I was 12, my father accidentally deleted all my computer files.  I have no memory of anything before that.)</para>
<para>But that&apos;s how I remember first learning about the difference between intensional and extensional definition.  To give an &quot;intensional definition&quot; is to define a word or phrase in terms of other words, as a dictionary does.  To give an &quot;extensional definition&quot; is to point to examples, as adults do when teaching children.  The preceding sentence gives an intensional definition of &quot;extensional definition&quot;, which makes it an extensional example of &quot;intensional definition&quot;.</para>
<para>In Hollywood Rationality and popular culture generally, &quot;rationalists&quot; are depicted as word-obsessed, floating in endless verbal space disconnected from reality.</para>
<para>But the actual Traditional Rationalists have long insisted on maintaining a tight connection to experience:</para>
<blockquote>
  <para> &quot;If you look into a textbook of chemistry for a definition of lithium, you may be told that it is that element whose atomic weight is 7 very nearly. But if the author has a more logical mind he will tell you that if you search among minerals that are vitreous, translucent, grey or white, very hard, brittle, and insoluble, for one which imparts a crimson tinge to an unluminous flame, this mineral being triturated with lime or witherite rats-bane, and then fused, can be partly dissolved in muriatic acid; and if this solution be evaporated, and the residue be extracted with sulphuric acid, and duly purified, it can be converted by ordinary methods into a chloride, which being obtained in the solid state, fused, and electrolyzed with half a dozen powerful cells, will yield a globule of a pinkish silvery metal that will float on gasolene; and the material of that is a specimen of lithium.&quot;</para>
  <para>        — Charles Sanders Peirce</para>
</blockquote>
<para>That&apos;s an example of &quot;logical mind&quot; as described by a genuine Traditional Rationalist, rather than a Hollywood scriptwriter.</para>
<para>But note:  Peirce isn&apos;t <emphasis>actually</emphasis> showing you a piece of lithium.  He didn&apos;t have pieces of lithium stapled to his book.  Rather he&apos;s giving you a treasure map—an intensionally defined procedure which, when executed, will lead you to an extensional example of lithium.  This is not the same as just tossing you a hunk of lithium, but it&apos;s not the same as saying &quot;atomic weight 7&quot; either.  (Though if you had <emphasis>sufficiently sharp</emphasis> eyes, saying &quot;3 protons&quot; might let you pick out lithium at a glance...)</para>
<para>So that is intensional and extensional <emphasis>definition., </emphasis>which is a way of telling someone else what you mean by a concept.  When I talked about &quot;definitions&quot; above, I talked about a way of <emphasis>communicating</emphasis> concepts—<emphasis>telling someone else</emphasis> what you mean by &quot;red&quot;, &quot;tiger&quot;, &quot;human&quot;, or &quot;lithium&quot;.  Now let&apos;s talk about the actual concepts themselves.</para>
<para>The actual intension of my &quot;tiger&quot; concept would be the neural pattern (in my temporal cortex) that inspects an incoming signal from the visual cortex to determine whether or not it is a tiger.</para>
<para>The actual extension of my &quot;tiger&quot; concept is everything I call a tiger.</para>
<para>Intensional definitions don&apos;t capture entire intensions; extensional definitions don&apos;t capture entire extensions.  If I point to just one tiger and say the word &quot;tiger&quot;, the communication may fail if they think I mean &quot;dangerous animal&quot; or &quot;male tiger&quot; or &quot;yellow thing&quot;.  Similarly, if I say &quot;dangerous yellow-black striped animal&quot;, without pointing to anything, the listener may visualize giant hornets.</para>
<para>You can&apos;t capture in words all the details of the cognitive concept—as it exists in your mind—that lets you recognize things as tigers or nontigers.  It&apos;s too large.  And you can&apos;t point to all the tigers you&apos;ve ever seen, let alone everything you <emphasis>would</emphasis> call a tiger.</para>
<para>The strongest definitions use a crossfire of intensional and extensional communication to nail down a concept.  Even so, you only communicate <emphasis>maps to</emphasis> concepts, or instructions for building concepts—you don&apos;t communicate the <emphasis>actual</emphasis> categories as they exist in your mind or in the world.</para>
<para>(Yes, with enough creativity you can construct exceptions to this rule, like &quot;Sentences Eliezer Yudkowsky has published containing the term &apos;huragaloni&apos; as of Feb 4, 2008&quot;.  I&apos;ve just shown you this concept&apos;s entire extension.  But except in mathematics, definitions are usually treasure maps, not treasure.)</para>
<para>So that&apos;s another reason you can&apos;t &quot;define a word any way you like&quot;:  You can&apos;t directly program concepts into someone else&apos;s brain.</para>
<para>Even within the Aristotelian paradigm, where we pretend that the definitions are the actual concepts, you don&apos;t have <emphasis>simultaneous </emphasis>freedom of intension and extension.  Suppose I define Mars as &quot;A huge red rocky sphere, around a tenth of Earth&apos;s mass and 50% further away from the Sun&quot;.  It&apos;s then a separate matter to show that this intensional definition matches some particular extensional thing in my experience, or indeed, that it matches any real thing whatsoever.  If instead I say &quot;That&apos;s Mars&quot; and point to a red light in the night sky, it becomes a separate matter to show that this extensional light matches any particular intensional definition I may propose—or any intensional beliefs I may have—such as &quot;Mars is the God of War&quot;.</para>
<para>But most of the brain&apos;s work of applying intensions happens sub-deliberately.  We aren&apos;t consciously aware that our identification of a red light as &quot;Mars&quot; is a separate matter from our verbal definition &quot;Mars is the God of War&quot;.  No matter what kind of intensional definition I make up to describe Mars, my mind believes that &quot;Mars&quot; refers to <link xl:href="http://en.wikipedia.org/wiki/Image:Mars_Hubble.jpg">this thingy</link>, and that it is the fourth planet in the Solar System.</para>
<para>When you take into account the way the human mind actually, pragmatically works, the notion &quot;I can define a word any way I like&quot; soon becomes &quot;I can believe anything I want about a fixed set of objects&quot; or &quot;I can move any object I want in or out of a fixed membership test&quot;.  Just as you can&apos;t usually convey a concept&apos;s whole intension in words because it&apos;s a big complicated neural membership test, you can&apos;t <emphasis>control</emphasis> the concept&apos;s entire intension because it&apos;s applied sub-deliberately.  This is why arguing that XYZ is true &quot;by definition&quot; is so popular.  If definition changes behaved like the empirical nullops they&apos;re supposed to be, no one would bother arguing them.  But abuse definitions just a little, and they turn into magic wands—in arguments, of course; not in reality.</para>

  
</section>

<section xml:id="item_DwtYPRuCxpXTrzG9m"
      xmlns="http://docbook.org/ns/docbook"
      version="5.0"
      xml:lang="en"
      xmlns:xlink="http://www.w3.org/1999/xlink"
      xmlns:xi="http://www.w3.org/2001/XInclude"
      xmlns:xl="http://www.w3.org/1999/xlink">
  <info>
    <title>My Wild and Reckless Youth</title>
    <bibliosource class="uri">
      <link xlink:href="https://www.lesswrong.com/posts/DwtYPRuCxpXTrzG9m/my-wild-and-reckless-youth"></link>
    </bibliosource>
    <pubdate doc_status="draft">2021-08-12</pubdate>
  </info>
  <indexterm><primary>Anticipated Experiences</primary></indexterm>
<indexterm><primary>Growth Stories</primary></indexterm>
  <para>It is said that parents do all the things they tell their children not to do, which is how they know not to do them. </para>
<para>Long ago, in the unthinkably distant past, I was a devoted Traditional Rationalist, conceiving myself skilled according to that kind, yet I knew not the Way of Bayes. When the young Eliezer was confronted with a mysterious-seeming question, the precepts of Traditional Rationality did not stop him from devising a Mysterious Answer. It is, by far, the most embarrassing mistake I made in my life, and I still wince to think of it.</para>
<para>What was my mysterious answer to a mysterious question? This I will not describe, for it would be a long tale and complicated. I was young, and a mere Traditional Rationalist who knew not the teachings of Tversky and Kahneman. I knew about Occam’s Razor, but not the conjunction fallacy. I thought I could get away with thinking complicated thoughts myself, in the literary style of the complicated thoughts I read in science books, not realizing that correct complexity is only possible when every step is pinned down overwhelmingly. Today, one of the chief pieces of advice I give to aspiring young rationalists is “Do not attempt long chains of reasoning or complicated plans.”</para>
<para>Nothing more than this need be said: even after I invented my “answer,” the phenomenon was still a mystery unto me, and possessed the same quality of wondrous impenetrability that it had at the start.</para>
<para>Make no mistake, that younger Eliezer was not stupid. All the errors of which the young Eliezer was guilty are still being made today by respected scientists in respected journals. It would have taken a subtler skill to protect him than ever he was taught as a Traditional Rationalist.</para>
<para>Indeed, the young Eliezer diligently and painstakingly followed the injunctions of Traditional Rationality in the course of going astray.</para>
<para>As a Traditional Rationalist, the young Eliezer was careful to ensure that his Mysterious Answer made a bold prediction of future experience. Namely, I expected future neurologists to discover that neurons were exploiting quantum gravity, a la Sir Roger Penrose. This required neurons to maintain a certain degree of quantum coherence, which was something you could look for, and find or not find. Either you observe that or you don’t, right?</para>
<para>But my hypothesis made no <emphasis>retrospective</emphasis> predictions. According to Traditional Science, retrospective predictions don’t count—so why bother making them? To a Bayesian, on the other hand, if a hypothesis does not <emphasis>today</emphasis> have a favorable likelihood ratio over “I don’t know,” it raises the question of why you <emphasis>today</emphasis> believe anything more complicated than “I don’t know.” But I knew not the Way of Bayes, so I was not thinking about likelihood ratios or focusing probability density. I had Made a Falsifiable Prediction; was this not the Law? </para>
<para>As a Traditional Rationalist, the young Eliezer was careful not to believe in magic, mysticism, carbon chauvinism, or anything of that sort. I proudly professed of my Mysterious Answer, “It is just physics like all the rest of physics!” As if you could save magic from being a cognitive isomorph of magic, by calling it quantum gravity. But I knew not the Way of Bayes, and did not see the level on which my idea was isomorphic to magic. I gave my <emphasis>allegiance</emphasis> to physics, but this did not save me; what does probability theory know of allegiances? I avoided everything that Traditional Rationality told me was forbidden, but what was left was still magic. </para>
<para>Beyond a doubt, my allegiance to Traditional Rationality helped me get out of the hole I dug myself into. If I hadn’t been a Traditional Rationalist, I would have been <emphasis>completely</emphasis> screwed. But Traditional Rationality still wasn’t enough to get it <emphasis>right</emphasis>. It just led me into different mistakes than the ones it had explicitly forbidden. </para>
<para>When I think about how my younger self very carefully followed the rules of Traditional Rationality in the course of getting the answer <emphasis>wrong</emphasis>, it sheds light on the question of why people who call themselves “rationalists” do not rule the world. You need <emphasis>one whole hell of a lot</emphasis> of rationality before it does anything but lead you into new and interesting mistakes. </para>
<para>Traditional Rationality is taught as an art, rather than a science; you read the biography of famous physicists describing the lessons life taught them, and you try to do what they tell you to do. But you haven’t lived their lives, and half of what they’re trying to describe is an instinct that has been trained into them.</para>
<para>The way Traditional Rationality is designed, it would have been acceptable for me to spend thirty years on my silly idea, so long as I succeeded in falsifying it eventually, and was honest with myself about what my theory predicted, and accepted the disproof when it arrived, et cetera. This is enough to let the Ratchet of Science click forward, but it’s a little harsh on the people who waste thirty years of their lives. Traditional Rationality is a walk, not a dance. It’s designed to get you to the truth <emphasis>eventually</emphasis>, and gives you all too much time to smell the flowers along the way. </para>
<para>Traditional Rationalists can agree to disagree. Traditional Rationality doesn’t have the <emphasis>ideal</emphasis> that thinking is an exact art in which there is only one correct probability estimate given the evidence. In Traditional Rationality, you’re allowed to guess, and then test your guess. But experience has taught me that if you don’t <emphasis>know</emphasis>, and you guess, you’ll end up being wrong. </para>
<para>The Way of Bayes is also an imprecise art, at least the way I’m holding forth upon it. These essays are still fumbling attempts to put into words lessons that would be better taught by experience. But at least there’s <emphasis>underlying</emphasis> math, plus experimental evidence from cognitive psychology on how humans actually think. Maybe that will be enough to cross the stratospherically high threshold required for a discipline that lets you actually get it right, instead of just constraining you into interesting new mistakes.</para>

  
</section>

<section xml:id="item_RgkqLqkg8vLhsYpfh"
      xmlns="http://docbook.org/ns/docbook"
      version="5.0"
      xml:lang="en"
      xmlns:xlink="http://www.w3.org/1999/xlink"
      xmlns:xi="http://www.w3.org/2001/XInclude"
      xmlns:xl="http://www.w3.org/1999/xlink">
  <info>
    <title>Лжепричинность</title>
    <bibliosource class="uri">
      <link xlink:href="https://www.lesswrong.com/posts/RgkqLqkg8vLhsYpfh/fake-causality"></link>
    </bibliosource>
    <pubdate doc_status="draft">2021-04-02</pubdate>
  </info>
  <indexterm><primary>Causality</primary></indexterm>
  <para>Флогистон — это ответ Европы XVIII века на первоэлемент огня, введённый греческими алхимиками. Зажги древесину и позволь ей сгореть. Что представляет из себя эта яркая оранжевая штука? Почему древесина превратилась в пепел? На оба эти вопроса химики XVIII века отвечали — «флогистон».</para>
<para>…и больше ничего. Это всё, в этом и заключался их ответ: «флогистон».</para>
<para>Флогистон покидал горящие вещества как видимое пламя. В результате горящие вещества теряли свой флогистон и становились пеплом, своим «истинным материалом». Огонь, помещённый в герметичный сосуд, быстро гас потому, что воздух насыщался флогистоном и больше не мог его вместить. Уголь почти не оставлял никакого пепла, потому что он почти полностью состоял из флогистона.</para>
<para>Разумеется, никто не использовал теорию флогистона для того, чтобы <emphasis role="italic">предсказать</emphasis> результат химического превращения. Алхимик сначала смотрел на результат, а затем при помощи флогистона <emphasis role="italic">объяснял</emphasis> его. Не было и намёка на то, чтобы флогистонщики предсказали прекращение горения в замкнутом сосуде; они, скорее, зажгли огонь в сосуде, увидели его угасание и затем сказали: «Должно быть, воздух насытился флогистоном». Теорию флогистона нельзя применить для того, чтобы выяснить, чего ты точно <emphasis role="italic">не сможешь</emphasis> увидеть. Она может объяснить всё.</para>
<para>Наука ещё только начинала выходить на сцену. Очень долго никто не осознавал, что в этой теории что-то не так. Встретив лжеобъяснение, очень легко не <emphasis role="italic">ощутить</emphasis> его фальшивость: потому они и опасны.</para>
<para>Современные специалисты предполагают, что люди думают о причино-следственных связях, используя нечто вроде направленных ациклических графов или байесовских сетей. Поскольку шел дождь, тротуар мокрый; поскольку тротуар мокрый, он скользкий:</para>
<informalfigure>
  <mediaobject>
    <imageobject role="html">
      <imagedata contentwidth="69.03%" fileref="./img/726b977654b9a6db1d77eecc20169b5e.png" format="PNG" scalefit="1"/>
    </imageobject>
    <imageobject role="fo">
      <imagedata contentdepth="100%" fileref="./img/726b977654b9a6db1d77eecc20169b5e.png" format="PNG" scalefit="1" width="100%"/>
    </imageobject>
  </mediaobject>
</informalfigure>
<para>Из этого можно вывести (а, имея байесовскую сеть, можно даже точно вычислить эту вероятность), что, если тротуар скользкий, то, вероятно, шёл дождь. Однако, если уже известно о мокрости тротуара, то сообщение о его скользкости не несёт в себе никакой новой информации о дожде.</para>
<para>Почему огонь горячий и яркий?</para>
<informalfigure>
  <mediaobject>
    <imageobject role="html">
      <imagedata contentwidth="58.03%" fileref="./img/d522f755828095bddb61dbd02595a1ea.png" format="PNG" scalefit="1"/>
    </imageobject>
    <imageobject role="fo">
      <imagedata contentdepth="100%" fileref="./img/d522f755828095bddb61dbd02595a1ea.png" format="PNG" scalefit="1" width="100%"/>
    </imageobject>
  </mediaobject>
</informalfigure>
<para>Это <emphasis role="italic">выглядит</emphasis> как объяснение. И в мозгу эта информация <emphasis role="italic">хранится</emphasis> в том же формате и под тем же расширением, что и «настоящие» объяснения. Но человеческий разум неспособен автоматически определить, что стрелка, соединяющая гипотезу с её возможными следствиями, никак не ограничивает пути, которыми могут проявляться эти следствия. Эффект знания задним числом делает ситуацию ещё хуже: люди могут считать, что гипотеза действительно ограничивает происходящее, хотя на самом деле гипотеза <olink targetdoc="item_PYQ2izdfDPTe5uJTG" targetptr="item_jiBFC7DcCrZjGmZnJ">подогнана</olink> под происходящее постфактум.</para>
<para>Современная трактовка вероятностных рассуждений о причинности может точно описать, в чём именно состояла ошибка флогистонщиков. Байесовские сети были разработаны для того, чтобы, кроме всего прочего, не учитывать свидетельства дважды в том случае, когда логический вывод между причиной и следствием возможен в обе стороны. Например, я добыл кусочек ненадёжной информации о том, что тротуар мокрый. Это заставляет меня подумать: «возможно, идёт дождь». Но если идёт дождь, то утверждение «тротуар мокрый» стало более правдоподобным, так? То же самое ведь касается и скользкости тротуара, верно? Но если тротуар скользкий, то он, скорее всего, мокрый — и тогда нужно опять повысить вероятность того, что идёт дождь.</para>
<para>Джуда Перл приводит в качестве метафоры алгоритм подсчёта солдат в колонне. Представьте, что вы стоите в колонне и видите рядом только двух солдат: одного спереди и одного сзади. Всего трое солдат. Вы спрашиваете своего соседа: «А сколько солдат видишь <emphasis role="italic">ты</emphasis>?» Он вертит головой и говорит: «Троих». Получается, всего солдат шесть. Очевидно, что так решать эту задачу совершенно не стоит.</para>
<para>Умнее будет спросить у стоящего впереди солдата: «Сколько солдат перед тобой?», и у стоящего позади: «Сколько солдат за тобой?». Сообщение с вопросом «сколько солдат перед тобой?» можно передать дальше без особых затруднений. Если я стою первым, то я передам назад «1 солдат впереди». Человек, стоящий прямо за мной, получит сообщение «1 солдат впереди» и скажет второму своему соседу «2 солдата впереди». В это же время кто-то получает сообщение «N солдат позади» и передаёт стоящему впереди солдату сообщение «N+1 солдат позади». Сколько же всего солдат? Сложите оба полученных числа и добавьте единицу для себя — это и есть общее число солдат в линии.</para>
<para>Ключевая идея состоит в том, что каждый солдат должен <emphasis role="italic">отдельно</emphasis> отслеживать эти два сообщения, прямое и обратное, и сложить их вместе только в конце. Нельзя добавлять солдат из обратного сообщения, которое ты получил, в прямое сообщение, которое ты передашь дальше. Разумеется, сообщение с общим числом солдат никогда не появляется в этой цепочке: никто не произносит этого числа вслух.</para>
<para>Аналогичный принцип применяется в строгих вероятностных рассуждениях о причинности. Получение из <emphasis role="italic">не связанного</emphasis> с мокрым тротуаром источника каких-либо свидетельств о дожде создаст прямое сообщение от узла [дождь] к узлу [мокрый тротуар], и тем самым усилит ожидание увидеть мокрый тротуар. Наблюдение мокрого тротуара создаст обратное сообщение, идущее к убеждению о дожде, а затем это сообщение распространится от узла [дождь] до всех его соседей, <emphasis role="italic">кроме</emphasis> узла [мокрый тротуар].Каждый кусочек свидетельства учитывается ровно единожды; корректировки никогда не застревают между узлами, скача туда и обратно. Точный алгоритм можно найти в классической книге <emphasis role="italic">«Probabilistic Reasoning in Intelligent Systems: Networks of Plausible Inference»</emphasis> Джуды Перла.</para>
<para>Так что же было неправильно в теории флогистона? Когда мы наблюдаем, что огонь горячий, узел [огонь] посылает обратное сообщение со свидетельством узлу [флогистон], вынуждая нас обновить убеждения о флогистоне. Но тогда мы не можем считать это успешным предсказанием теории флогистона. Сообщение должно идти в единственном направлении, не отражаясь назад.</para>
<para>Увы, для обновления сетей убеждений люди используют не строгий алгоритм, а его грубое приближение. Мы изучаем родительские узлы, наблюдая за дочерними узлами, и предсказываем поведение дочерних узлов, используя убеждения о родительских узлах. Но ящик с документацией по прямым сообщениям не отделён от ящика с документацией по обратным сообщениям толстой непроницаемой стеной. Мы просто помним: «флогистон горячий, и <emphasis role="italic">из-за этого</emphasis> огонь тоже горячий». Всё это выглядит так, будто теория флогистона предсказывает «горячесть» огня. Или, что ещё хуже, нам кажется: <emphasis role="italic">«флогистон делает огонь горячим»</emphasis>.</para>
<para>Лишь после того, как кто-нибудь заметит полное отсутствие предсказаний заранее, не ограничивающий ожиданий причинно-следственный узел получит ярлык «фальшивка». До этого момента он не будет отличаться от остальных узлов в сети убеждений. Утверждение <emphasis role="italic">«флогистон делает огонь горячим»</emphasis> ощущается фактом точно так же, как и все остальные известные тебе факты.</para>
<para>Правильно спроектированный ИИ заметит проблему мгновенно. Для этого не понадобится какой-нибудь особенной заплатки, нужен всего лишь правильный учёт происходящего в сети убеждений (к сожалению, в отличие от правильно спроектированных ИИ, люди не способны переписывать свой исходный код, чтобы исправить найденные ошибки).</para>
<para>Рассуждения об «эффекте знания задним числом» — это просто способ не привлекая технических терминов рассказать о том, что люди не разделяют прямые и обратные сообщения, из-за чего прямые сообщения могут загрязняться обратными.</para>
<para>Люди, пошедшие по пути флогистона, не намеревались стать дураками. Ни один учёный не желает застрять в тупике. Не скрываются ли лжеобъяснения в недрах <emphasis role="italic">твоего</emphasis> разума? Если они там есть, то к ним определённо не приклеен ярлык «лжеобъяснение», и поэтому поиска по ключевому слову «фальшивка» явно недостаточно для того, чтобы их обнаружить.</para>
<para>Проверить, насколько хорошо теория «предсказывает» уже известные тебе факты, также недостаточно: эффект знания задним числом обесценит все усилия. Предсказывать нужно на завтра, а не на вчера. Лишь так можно быть уверенным в том, что захламлённый человеческий разум действительно посылает чистое прямое сообщение.</para>

  
</section>

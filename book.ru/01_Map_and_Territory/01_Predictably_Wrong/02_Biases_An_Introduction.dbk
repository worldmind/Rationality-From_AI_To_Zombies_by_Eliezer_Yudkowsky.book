<section xml:id="item_ptxnyfLWqRZ98wnYi"
      xmlns="http://docbook.org/ns/docbook"
      version="5.0"
      xml:lang="en"
      xmlns:xlink="http://www.w3.org/1999/xlink"
      xmlns:xi="http://www.w3.org/2001/XInclude"
      xmlns:xl="http://www.w3.org/1999/xlink">
  <info>
    <title>Biases: An Introduction</title>
    <bibliosource class="uri">
      <link xlink:href="https://www.lesswrong.com/posts/ptxnyfLWqRZ98wnYi/biases-an-introduction"></link>
    </bibliosource>
    <pubdate doc_status="draft">2023-05-09</pubdate>
  </info>
  <indexterm><primary>Heuristics &amp; Biases</primary></indexterm>
<indexterm><primary>Rationality</primary></indexterm>
  <para>Представьте себе урну с 70 белыми и 30 красными шарами; вы вытаскиваете 10 наугад.</para>
<para>Возможно, 3 из них будут красными, и вы верно угадаете, сколько всего красных шаров в урне. Или, возможно, у вас будет 4 красных шара, а может быть, другое число. И тогда вы получите неверное общее число.</para>
<para>This random error is the cost of incomplete knowledge, and as errors go, it’s not so bad. Your estimates won’t be incorrect <emphasis role="italic">on average</emphasis>, and the more you learn, the smaller your error will tend to be.</para>
<para>On the other hand, suppose that the white balls are heavier, and sink to the bottom of the urn. Then your sample may be unrepresentative in a consistent direction.</para>
<para><emphasis role="italic">That</emphasis> kind of error is called “statistical bias.” When your method of learning about the world is biased, learning more may not help. Acquiring more data can even consistently <emphasis role="italic">worsen</emphasis> a biased prediction.</para>
<para>If you’re used to holding knowledge and inquiry in high esteem, this is a scary prospect. If we want to be sure that learning more will help us, rather than making us worse off than we were before, we need to discover and correct for biases in our data.</para>
<para>The idea of <emphasis role="italic">cognitive bias</emphasis> in psychology works in an analogous way. A cognitive bias is a systematic error in <emphasis role="italic">how we think</emphasis>, as opposed to a random error or one that’s merely caused by our ignorance. Whereas statistical bias skews a sample so that it less closely resembles a larger population, cognitive biases skew our thinking so that it less accurately tracks the truth (or less reliably serves our other goals).</para>
<para>Maybe you have an optimism bias, and you find out that the red balls can be used to treat a rare tropical disease besetting your brother, and you end up overestimating how many red balls the urn contains because you <emphasis role="italic">wish</emphasis> the balls were mostly red.</para>
<para>Like statistical biases, cognitive biases can distort our view of reality, they can’t always be fixed by just gathering more data, and their effects can add up over time. But when the miscalibrated measuring instrument you’re trying to fix is <emphasis role="italic">you</emphasis>, debiasing is a unique challenge.</para>
<para>Still, this is an obvious place to start. For if you can’t trust your brain, how can you trust anything else?</para>
<section>
  <title>Noticing Bias</title>
  <para>Imagine meeting someone for the first time, and knowing nothing about them except that they’re shy.</para>
  <para>Question: Is it more likely that this person is a librarian, or a salesperson?</para>
  <para>Most people answer “librarian.” Which is a mistake: shy salespeople are much more common than shy librarians, because salespeople in general are much more common than librarians—seventy-five times as common, in the United States.<footnote xml:id="fn_32193002fdf5ed200d87f02f4051cf97">
      <para> Wayne Weiten, <emphasis role="italic">Psychology: Themes and Variations, Briefer Version, Eighth Edition</emphasis> (Cengage Learning, 2010).</para>
    </footnote>
</para>
  <para>This is <emphasis role="italic">base rate neglect</emphasis>: grounding one’s judgments in how well sets of characteristics feel like they fit together, and neglecting how common each characteristic is in the population at large.<footnote xml:id="fn_9c13c0e13db8da4a65b1c9bef48a836f">
      <para> Richards J. Heuer, <emphasis role="italic">Psychology of Intelligence Analysis</emphasis> (Center for the Study of Intelligence, Central Intelligence Agency, 1999) .</para>
    </footnote>
 Another example of a cognitive bias is the —people’s tendency to feel committed to things they’ve spent resources on in the past, when they should be cutting their losses and moving on.</para>
  <para>Knowing about these biases, unfortunately, doesn’t make you immune to them. It doesn’t even mean you’ll be able to notice them in action.</para>
  <para>In a study of <emphasis role="italic">bias blindness</emphasis>, experimental subjects predicted that they would have a harder time neutrally evaluating the quality of paintings if they knew the paintings were by famous artists. And indeed, these subjects exhibited the very bias they had predicted when the experimenters later tested their prediction. When asked <emphasis role="italic">afterward</emphasis>, however, the very same subjects claimed that their assessments of the paintings had been objective and unaffected by the bias.<footnote xml:id="fn_200f93d907b4417638babb271292bd91">
      <para> Katherine Hansen et al., “People Claim Objectivity After Knowingly Using Biased Strategies,” <emphasis role="italic">Personality and Social Psychology Bulletin</emphasis> 40, no. 6 (2014): 691–699 .</para>
    </footnote>
</para>
  <para>Even when we correctly identify others’ biases, we exhibit a <emphasis role="italic">bias blind spot</emphasis> when it comes to our own flaws.<footnote xml:id="fn_8d1b692894a0ce70149218e8a64eb23d">
      <para> Emily Pronin, Daniel Y. Lin, and Lee Ross, “The Bias Blind Spot: Perceptions of Bias in Self versus Others,” <emphasis role="italic">Personality and Social Psychology Bulletin</emphasis> 28, no. 3 (2002): 369–381 .</para>
    </footnote>
 Failing to detect any “biased-feeling thoughts” when we introspect, we draw the conclusion that we must just be less biased than everyone else.<footnote xml:id="fn_36b216332d474c394264134ff38a03d8">
      <para> Joyce Ehrlinger, Thomas Gilovich, and Lee Ross, “Peering Into the Bias Blind Spot: People’s Assessments of Bias in Themselves and Others,” <emphasis role="italic">Personality and Social Psychology Bulletin</emphasis> 31, no. 5 (2005): 680–692.</para>
    </footnote>
</para>
  <para>Yet it <emphasis role="italic">is</emphasis> possible to recognize and overcome biases. It’s just not trivial. It’s known that subjects can reduce base rate neglect, for example, by thinking of probabilities as frequencies of objects or events.</para>
  <para>The approach to debiasing in this book is to communicate a systematic understanding of <emphasis role="italic">why good reasoning works</emphasis>, and of how the brain falls short of it. To the extent this volume does its job, its approach can be compared to the one described in Serfas (2010), who notes that “years of financially related work experience” didn’t affect people’s susceptibility to the sunk cost bias, whereas “the number of accounting courses attended” did help.</para>
  <blockquote>
    <para> As a consequence, it might be necessary to distinguish between experience and expertise, with expertise meaning “the development of a schematic principle that involves conceptual understanding of the problem,” which in turn enables the decision maker to recognize particular biases. However, using expertise as countermeasure requires more than just being familiar with the situational content or being an expert in a particular domain. It requires that one fully understand the underlying rationale of the respective bias, is able to spot it in the particular setting, and also has the appropriate tools at hand to counteract the bias.<footnote xml:id="fn_aef9854dd10a146ee09a96ec6f4c369d">
        <para> Sebastian Serfas, <emphasis role="italic">Cognitive Biases in the Capital Investment Context: Theoretical Considerations and Empirical Experiments on Violations of Normative Rationality</emphasis> (Springer, 2010).</para>
      </footnote>
</para>
  </blockquote>
  <para>The goal of this book is to lay the groundwork for creating rationality “expertise.” That means acquiring a deep understanding of the structure of a very general problem: human bias, self-deception, and the thousand paths by which sophisticated thought can defeat itself.</para>
</section>
<section>
  <title>A Word About This Text</title>
  <para><emphasis role="italic">Map and Territory</emphasis> began its life as a series of essays by decision theorist Eliezer Yudkowsky, published between 2006 and 2009 on the economics blog <emphasis role="italic">Overcoming Bias</emphasis> and its spin-off community blog <link xl:href="http://lesswrong.com">Less Wrong</link>. Thematically linked essays were grouped together in “sequences,” and thematically linked sequences were grouped into books. <emphasis role="italic">Map and Territory</emphasis> is the first of six such books, with the series as a whole going by the name <emphasis role="italic">Rationality: From AI to Zombies</emphasis>.<footnote xml:id="fn_18f5dad860f082b4c521d997fd8991db">
      <para> The first edition of <emphasis role="italic">Rationality: From AI to Zombies</emphasis> was released as a single sprawling ebook, before the series was edited and split up into separate volumes. The full book can also be found on <link xl:href="https://www.lesswrong.com/rationality">http://lesswrong.com/rationality</link>.</para>
    </footnote>
</para>
  <para>In style, this series run the gamut from “lively textbook” to “compendium of vignettes” to “riotous manifesto,” and the content is correspondingly varied. The resultant rationality primer is frequently personal and irreverent—drawing, for example, from Yudkowsky’s experiences with his Orthodox Jewish mother (a psychiatrist) and father (a physicist), and from conversations on chat rooms and mailing lists. Readers who are familiar with Yudkowsky from <link xl:href="http://hpmor.com/"><emphasis role="italic">Harry Potter and the Methods of Rationality</emphasis></link>, his science-oriented take-off of J.K. Rowling’s <emphasis role="italic">Harry Potter</emphasis> books, will recognize the same iconoclasm, and many of the same themes.</para>
  <para>The philosopher Alfred Korzybski once wrote: “A map <emphasis role="italic">is not</emphasis> the territory it represents, but, if correct, it has a <emphasis role="italic">similar structure</emphasis> to the territory, which accounts for its usefulness.” And what can be said of maps here, as Korzybski noted, can also be said of beliefs, and assertions, and words.</para>
  <para>“The map is not the territory.” This deceptively simple claim is the organizing idea behind this book, and behind the four sequences of essays collected here: <olink targetdoc="item_PYQ2izdfDPTe5uJTG" targetptr="item_5g5TkQTe9rmPS5vvM"><emphasis role="bold">Predictably Wrong</emphasis></olink>, which concerns the systematic ways our beliefs fail to map the real world; <olink targetdoc="item_PYQ2izdfDPTe5uJTG" targetptr="item_7gRSERQZbqTuLX5re"><emphasis role="bold">Fake Beliefs</emphasis></olink>, on what makes a belief a “map” in the first place; <olink targetdoc="item_PYQ2izdfDPTe5uJTG" targetptr="item_zpCiuR4T343j9WkcK"><emphasis role="bold">Noticing Confusion</emphasis></olink>, on how this world-mapping thing our brains do actually works; and <olink targetdoc="item_PYQ2izdfDPTe5uJTG" targetptr="item_5uZQHpecjn7955faL"><emphasis role="bold">Mysterious Answers</emphasis></olink>, which collides these points together. The book then concludes with “The Simple Truth,” a stand-alone dialogue on the idea of truth itself.</para>
  <para>Humans aren’t rational; but, as behavioral economist Dan Ariely notes, we’re <emphasis role="italic">predictably</emphasis> irrational. There are patterns to how we screw up. And there are patterns to how we behave when we <emphasis role="italic">don’t</emphasis> screw up. Both admit of fuller understanding, and with it, the hope of leaning on that understanding to build a better future for ourselves.</para>
</section>

  
</section>
